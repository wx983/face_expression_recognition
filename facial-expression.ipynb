{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a202e6db",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:04.662172Z",
     "iopub.status.busy": "2023-11-13T03:50:04.661543Z",
     "iopub.status.idle": "2023-11-13T03:50:08.749746Z",
     "shell.execute_reply": "2023-11-13T03:50:08.748938Z"
    },
    "papermill": {
     "duration": 4.09991,
     "end_time": "2023-11-13T03:50:08.752159",
     "exception": false,
     "start_time": "2023-11-13T03:50:04.652249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy  as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae679c7",
   "metadata": {
    "papermill": {
     "duration": 0.00696,
     "end_time": "2023-11-13T03:50:08.767191",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.760231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "689edc08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:08.783014Z",
     "iopub.status.busy": "2023-11-13T03:50:08.782519Z",
     "iopub.status.idle": "2023-11-13T03:50:08.787109Z",
     "shell.execute_reply": "2023-11-13T03:50:08.786124Z"
    },
    "papermill": {
     "duration": 0.014875,
     "end_time": "2023-11-13T03:50:08.789043",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.774168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 20  # 时间：3轮 一分钟\n",
    "lr = 0.005\n",
    "batchsize = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63715c",
   "metadata": {
    "papermill": {
     "duration": 0.006808,
     "end_time": "2023-11-13T03:50:08.803041",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.796233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a554f5b4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:08.819049Z",
     "iopub.status.busy": "2023-11-13T03:50:08.818717Z",
     "iopub.status.idle": "2023-11-13T03:50:08.822612Z",
     "shell.execute_reply": "2023-11-13T03:50:08.821736Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.014168,
     "end_time": "2023-11-13T03:50:08.824471",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.810303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b37580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:08.839578Z",
     "iopub.status.busy": "2023-11-13T03:50:08.839283Z",
     "iopub.status.idle": "2023-11-13T03:50:08.843522Z",
     "shell.execute_reply": "2023-11-13T03:50:08.842715Z"
    },
    "papermill": {
     "duration": 0.01385,
     "end_time": "2023-11-13T03:50:08.845315",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.831465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3daca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:08.860543Z",
     "iopub.status.busy": "2023-11-13T03:50:08.860267Z",
     "iopub.status.idle": "2023-11-13T03:50:08.872472Z",
     "shell.execute_reply": "2023-11-13T03:50:08.871648Z"
    },
    "papermill": {
     "duration": 0.021933,
     "end_time": "2023-11-13T03:50:08.874407",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.852474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generate_data():\n",
    "    def __init__(self, datapath,savepath):  # datapath：原始csv文件，savepath：划分成训练集和验证集的csv文件\n",
    "        \"\"\"\n",
    "        Generate_data class\n",
    "        Two methods to be used\n",
    "        1-split_test\n",
    "        2-save_images\n",
    "        [Note] that you have to split the public and private from fer2013 file\n",
    "        \"\"\"\n",
    "        self.data_path = datapath   \n",
    "        self.save_path = savepath\n",
    "        \n",
    "    def split_test(self, val_filename= 'val'):   # 输入train.csv文件，输出两个csv文件，分别是train.csv和val.csv，也即是将原始训练集划分为训练集和验证集\n",
    "        \"\"\"\n",
    "        Helper function to split the validation and train data from general train file.\n",
    "            params:-\n",
    "                data_path = path to the folder that contains the train data file\n",
    "        \"\"\"\n",
    "        train_csv_path = self.data_path +\"/\"+ 'train.csv'\n",
    "        train = pd.read_csv(train_csv_path)\n",
    "        # This is data split, u can use for creating test_data.\n",
    "        \n",
    "        validation_data = pd.DataFrame(train.iloc[:3589,:])  # 划分前3590个数据为验证集   经过DataFrame后，生成的csv文件会多第一列，为索引\n",
    "        train_data = pd.DataFrame(train.iloc[3589:,:])       # 划分后2w多个数据为训练集\n",
    "        train_data.to_csv(self.save_path+\"/train.csv\")       # 导出为CSV文件\n",
    "        validation_data.to_csv(self.save_path+\"/\"+val_filename+\".csv\")  # 导出为CSV文件\n",
    "        print(\"Done splitting the train file into validation & train\")\n",
    "\n",
    "    def str_to_image(self, str_img = ' '):  # 将数据文件中，每一行字符串所代表的一张图片，转换为一张48*48的Image图片\n",
    "        '''\n",
    "        Convert string pixels from the csv file into image object\n",
    "            params:- take an image string\n",
    "            return :- return PIL image object\n",
    "        '''\n",
    "        imgarray_str = str_img.split(' ')  # 从图片字符串split，形成列表\n",
    "        imgarray = np.asarray(imgarray_str,dtype=np.uint8).reshape(48,48) # 将输入（字符串列表） 转换为 数组\n",
    "        return Image.fromarray(imgarray)  # 将数组 转换为 图像Image类\n",
    "\n",
    "    def save_images(self, datatype='train'):\n",
    "        '''\n",
    "        save_images is a function responsible for saving images from data files e.g(train, test) in a desired folder\n",
    "            params:-\n",
    "            datatype= str e.g (train, val, test)\n",
    "        '''\n",
    "        foldername= self.save_path + \"/\" + datatype\n",
    "        if datatype == 'test':  # 测试集是提交kaggle比赛需要的，本地跑不需要，但这个代码不删除也可以，不影响\n",
    "            csvfile_path= self.data_path+\"/\"+datatype+'.csv'  # 测试集放在data_path下，和原始未划分的训练集放在一个文件夹下\n",
    "        else:\n",
    "            csvfile_path= self.save_path+'/'+datatype+'.csv'\n",
    "        if not os.path.exists(foldername):\n",
    "            os.mkdir(foldername)\n",
    "\n",
    "        data = pd.read_csv(csvfile_path)\n",
    "        images = data['pixels'] # dataframe to series pandas\n",
    "        numberofimages = images.shape[0]  # [5,]  所以是shape[0]\n",
    "        if datatype=='train':\n",
    "            print(\"训练集数据量为：\", numberofimages, \"条\")\n",
    "        for index in tqdm(range(numberofimages)):  # tqdm：设置打印进度条显示\n",
    "            img = self.str_to_image(images[index]) # 将字符串转换为Image文件\n",
    "            img.save(os.path.join(foldername,'{}{}.jpg'.format(datatype,index)),'JPEG')  # 以JPEG格式 保存图片 但实际保存为了jpg格式，不知道为什么，但无伤大雅\n",
    "        print('Done saving {} data'.format((foldername)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fd59fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:08.890031Z",
     "iopub.status.busy": "2023-11-13T03:50:08.889445Z",
     "iopub.status.idle": "2023-11-13T03:50:48.000540Z",
     "shell.execute_reply": "2023-11-13T03:50:47.999495Z"
    },
    "papermill": {
     "duration": 39.122277,
     "end_time": "2023-11-13T03:50:48.003664",
     "exception": false,
     "start_time": "2023-11-13T03:50:08.881387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done splitting the train file into validation & train\n",
      "25120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25120/25120 [00:12<00:00, 1973.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data/train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7178/7178 [00:03<00:00, 1867.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data/test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3589/3589 [00:01<00:00, 1820.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data/val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path='challenges-in-representation-learning-facial-expression-recognition-challenge'\n",
    "save_path='data'\n",
    "\n",
    "generate_dataset = Generate_data(data_path, save_path)\n",
    "generate_dataset.split_test()\n",
    "generate_dataset.save_images('train')\n",
    "generate_dataset.save_images('test')\n",
    "generate_dataset.save_images('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012f412",
   "metadata": {
    "papermill": {
     "duration": 0.02283,
     "end_time": "2023-11-13T03:50:48.049784",
     "exception": false,
     "start_time": "2023-11-13T03:50:48.026954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724bdca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:48.098126Z",
     "iopub.status.busy": "2023-11-13T03:50:48.097275Z",
     "iopub.status.idle": "2023-11-13T03:50:48.106254Z",
     "shell.execute_reply": "2023-11-13T03:50:48.105372Z"
    },
    "papermill": {
     "duration": 0.035231,
     "end_time": "2023-11-13T03:50:48.108246",
     "exception": false,
     "start_time": "2023-11-13T03:50:48.073015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Plain_Dataset(Dataset):\n",
    "    def __init__(self,img_dir,datatype,transform,csv_file='None'):\n",
    "        '''\n",
    "        Pytorch Dataset class\n",
    "        params:-\n",
    "                 csv_file : the path of the csv file    (train, validation, test)\n",
    "                 img_dir  : the directory of the images (train, validation, test)\n",
    "                 datatype : string for searching along the image_dir (train, val, test)\n",
    "                 transform: pytorch transformation over the data\n",
    "        return :-\n",
    "                 image, labels\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.datatype = datatype\n",
    "        if self.datatype != 'test':\n",
    "            self.csv_file = pd.read_csv(csv_file)\n",
    "            self.labels = self.csv_file['emotion']  # pandas中的Series可以理解为一种特殊的列表，索引可以不是整数，可以是字符，有点像字典\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist() # 将张量转换为列表\n",
    "        img = Image.open(self.img_dir + '/' + self.datatype + str(idx) + '.jpg')\n",
    "        if self.transform :    # 图像预处理\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.datatype != 'test':\n",
    "            labels = np.array(self.labels[idx])   # 需要将字符串转换为数组 asarray是浅拷贝，而array属于深拷贝，会另外开辟内存空间\n",
    "            labels = torch.from_numpy(labels).long()\n",
    "            return(img, labels)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde6bb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:48.155131Z",
     "iopub.status.busy": "2023-11-13T03:50:48.154812Z",
     "iopub.status.idle": "2023-11-13T03:50:48.159124Z",
     "shell.execute_reply": "2023-11-13T03:50:48.158260Z"
    },
    "papermill": {
     "duration": 0.029985,
     "end_time": "2023-11-13T03:50:48.160943",
     "exception": false,
     "start_time": "2023-11-13T03:50:48.130958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traincsv_file='data/train.csv'\n",
    "validationcsv_file='data/val.csv'\n",
    "\n",
    "train_img_dir='data/train'\n",
    "validation_img_dir='data/val'\n",
    "test_img_dir='data/test'\n",
    "\n",
    "# print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af29c0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:48.207920Z",
     "iopub.status.busy": "2023-11-13T03:50:48.207566Z",
     "iopub.status.idle": "2023-11-13T03:50:50.467861Z",
     "shell.execute_reply": "2023-11-13T03:50:50.466836Z"
    },
    "papermill": {
     "duration": 2.286623,
     "end_time": "2023-11-13T03:50:50.470161",
     "exception": false,
     "start_time": "2023-11-13T03:50:48.183538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n",
    "validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n",
    "test_dataset= Plain_Dataset( img_dir = test_img_dir, datatype = 'test', transform = transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle = True, num_workers=0)\n",
    "val_loader   = DataLoader(validation_dataset, batch_size=batchsize, shuffle = True, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batchsize, shuffle = True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d60659f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:50.518771Z",
     "iopub.status.busy": "2023-11-13T03:50:50.517881Z",
     "iopub.status.idle": "2023-11-13T03:50:50.539189Z",
     "shell.execute_reply": "2023-11-13T03:50:50.538306Z"
    },
    "papermill": {
     "duration": 0.047902,
     "end_time": "2023-11-13T03:50:50.541229",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.493327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe9f15",
   "metadata": {
    "papermill": {
     "duration": 0.023078,
     "end_time": "2023-11-13T03:50:50.587989",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.564911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ba66844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:50.635737Z",
     "iopub.status.busy": "2023-11-13T03:50:50.635357Z",
     "iopub.status.idle": "2023-11-13T03:50:50.649286Z",
     "shell.execute_reply": "2023-11-13T03:50:50.648524Z"
    },
    "papermill": {
     "duration": 0.040269,
     "end_time": "2023-11-13T03:50:50.651231",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.610962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Deep_Emotion(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Deep_Emotion class contains the network architecture.\n",
    "        '''\n",
    "        super(Deep_Emotion,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,3)\n",
    "        self.conv2 = nn.Conv2d(10,10,3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(10,10,3)\n",
    "        self.conv4 = nn.Conv2d(10,10,3)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(10)\n",
    "\n",
    "        self.fc1 = nn.Linear(810,50)\n",
    "        self.fc2 = nn.Linear(50,7)  # 七分类问题\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(640, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 640)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self,input):\n",
    "        out = self.stn(input)\n",
    "\n",
    "        out = F.relu(self.conv1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.pool2(out))\n",
    "\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.norm(self.conv4(out))\n",
    "        out = F.relu(self.pool4(out))\n",
    "\n",
    "        out = F.dropout(out)\n",
    "        out = out.view(-1, 810)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282a3be",
   "metadata": {
    "papermill": {
     "duration": 0.070954,
     "end_time": "2023-11-13T03:50:50.745347",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.674393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d614231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:50.793640Z",
     "iopub.status.busy": "2023-11-13T03:50:50.793252Z",
     "iopub.status.idle": "2023-11-13T03:50:50.803755Z",
     "shell.execute_reply": "2023-11-13T03:50:50.802909Z"
    },
    "papermill": {
     "duration": 0.03686,
     "end_time": "2023-11-13T03:50:50.805676",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.768816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Train(net, epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device) # 对于选择cpu还是gpu作为运算器，这行代码必要\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)  # 前者为最大值，后者为最大值的索引，即preds表示七分类中具体属于哪个类别\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "\n",
    "        validation_loss =  validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    print(\"===================================Training Finished===================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44393e49",
   "metadata": {
    "papermill": {
     "duration": 0.023228,
     "end_time": "2023-11-13T03:50:50.851867",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.828639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f768672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:50.899772Z",
     "iopub.status.busy": "2023-11-13T03:50:50.898886Z",
     "iopub.status.idle": "2023-11-13T03:50:50.961876Z",
     "shell.execute_reply": "2023-11-13T03:50:50.960906Z"
    },
    "papermill": {
     "duration": 0.088966,
     "end_time": "2023-11-13T03:50:50.963955",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.874989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device to cuda\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18dad7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:51.012559Z",
     "iopub.status.busy": "2023-11-13T03:50:51.011726Z",
     "iopub.status.idle": "2023-11-13T03:50:53.987725Z",
     "shell.execute_reply": "2023-11-13T03:50:53.986739Z"
    },
    "papermill": {
     "duration": 3.002314,
     "end_time": "2023-11-13T03:50:53.989736",
     "exception": false,
     "start_time": "2023-11-13T03:50:50.987422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deep_Emotion(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=810, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=7, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=640, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "net = Deep_Emotion()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17e3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:54.038314Z",
     "iopub.status.busy": "2023-11-13T03:50:54.037958Z",
     "iopub.status.idle": "2023-11-13T03:50:54.042968Z",
     "shell.execute_reply": "2023-11-13T03:50:54.042104Z"
    },
    "papermill": {
     "duration": 0.031634,
     "end_time": "2023-11-13T03:50:54.044996",
     "exception": false,
     "start_time": "2023-11-13T03:50:54.013362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion= nn.CrossEntropyLoss()\n",
    "optmizer= optim.Adam(net.parameters(),lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e186265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:50:54.093648Z",
     "iopub.status.busy": "2023-11-13T03:50:54.092845Z",
     "iopub.status.idle": "2023-11-13T03:51:40.234436Z",
     "shell.execute_reply": "2023-11-13T03:51:40.233523Z"
    },
    "papermill": {
     "duration": 46.168361,
     "end_time": "2023-11-13T03:51:40.236773",
     "exception": false,
     "start_time": "2023-11-13T03:50:54.068412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Start Training===================================\n",
      "Epoch: 1 \tTraining Loss: 0.01107255 \tValidation Loss 0.01149050 \tTraining Acuuarcy 45.243% \tValidation Acuuarcy 44.609%\n",
      "Epoch: 2 \tTraining Loss: 0.01091114 \tValidation Loss 0.01146732 \tTraining Acuuarcy 46.334% \tValidation Acuuarcy 45.277%\n",
      "Epoch: 3 \tTraining Loss: 0.01076095 \tValidation Loss 0.01155597 \tTraining Acuuarcy 46.919% \tValidation Acuuarcy 43.550%\n",
      "Epoch: 4 \tTraining Loss: 0.01070111 \tValidation Loss 0.01130113 \tTraining Acuuarcy 47.468% \tValidation Acuuarcy 45.472%\n",
      "Epoch: 5 \tTraining Loss: 0.01060776 \tValidation Loss 0.01129115 \tTraining Acuuarcy 47.488% \tValidation Acuuarcy 45.695%\n",
      "Epoch: 6 \tTraining Loss: 0.01052435 \tValidation Loss 0.01104624 \tTraining Acuuarcy 48.193% \tValidation Acuuarcy 46.336%\n",
      "Epoch: 7 \tTraining Loss: 0.01049874 \tValidation Loss 0.01114440 \tTraining Acuuarcy 48.674% \tValidation Acuuarcy 45.639%\n",
      "Epoch: 8 \tTraining Loss: 0.01040370 \tValidation Loss 0.01104635 \tTraining Acuuarcy 48.794% \tValidation Acuuarcy 46.197%\n",
      "Epoch: 9 \tTraining Loss: 0.01038565 \tValidation Loss 0.01112462 \tTraining Acuuarcy 49.128% \tValidation Acuuarcy 46.420%\n",
      "Epoch: 10 \tTraining Loss: 0.01034136 \tValidation Loss 0.01117444 \tTraining Acuuarcy 49.407% \tValidation Acuuarcy 47.116%\n",
      "Epoch: 11 \tTraining Loss: 0.01031428 \tValidation Loss 0.01152223 \tTraining Acuuarcy 49.526% \tValidation Acuuarcy 46.030%\n",
      "Epoch: 12 \tTraining Loss: 0.01026184 \tValidation Loss 0.01108977 \tTraining Acuuarcy 49.789% \tValidation Acuuarcy 46.838%\n",
      "Epoch: 13 \tTraining Loss: 0.01021089 \tValidation Loss 0.01081484 \tTraining Acuuarcy 50.139% \tValidation Acuuarcy 47.478%\n",
      "Epoch: 14 \tTraining Loss: 0.01019429 \tValidation Loss 0.01117720 \tTraining Acuuarcy 50.410% \tValidation Acuuarcy 46.754%\n",
      "Epoch: 15 \tTraining Loss: 0.01013758 \tValidation Loss 0.01125501 \tTraining Acuuarcy 50.629% \tValidation Acuuarcy 46.392%\n",
      "Epoch: 16 \tTraining Loss: 0.01020839 \tValidation Loss 0.01091245 \tTraining Acuuarcy 50.076% \tValidation Acuuarcy 46.643%\n",
      "Epoch: 17 \tTraining Loss: 0.01011430 \tValidation Loss 0.01101140 \tTraining Acuuarcy 50.490% \tValidation Acuuarcy 46.225%\n",
      "Epoch: 18 \tTraining Loss: 0.01011237 \tValidation Loss 0.01130907 \tTraining Acuuarcy 50.744% \tValidation Acuuarcy 46.949%\n",
      "Epoch: 19 \tTraining Loss: 0.01005474 \tValidation Loss 0.01101129 \tTraining Acuuarcy 50.736% \tValidation Acuuarcy 47.451%\n",
      "Epoch: 20 \tTraining Loss: 0.01003102 \tValidation Loss 0.01107027 \tTraining Acuuarcy 50.478% \tValidation Acuuarcy 47.478%\n",
      "===================================Training Finished===================================\n"
     ]
    }
   ],
   "source": [
    "Train(net, epochs, train_loader, val_loader, criterion, optmizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14b90c",
   "metadata": {
    "papermill": {
     "duration": 0.023396,
     "end_time": "2023-11-13T03:51:40.284345",
     "exception": false,
     "start_time": "2023-11-13T03:51:40.260949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6bf8115",
   "metadata": {
    "papermill": {
     "duration": 0.023236,
     "end_time": "2023-11-13T03:51:40.331065",
     "exception": false,
     "start_time": "2023-11-13T03:51:40.307829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f022f912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:51:40.381031Z",
     "iopub.status.busy": "2023-11-13T03:51:40.380647Z",
     "iopub.status.idle": "2023-11-13T03:51:43.400330Z",
     "shell.execute_reply": "2023-11-13T03:51:43.399359Z"
    },
    "papermill": {
     "duration": 3.047271,
     "end_time": "2023-11-13T03:51:43.402744",
     "exception": false,
     "start_time": "2023-11-13T03:51:40.355473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mi:\\深度学习项目\\KaggleCode_facial-expression-recoginition\\facial-expression.ipynb 单元格 25\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/KaggleCode_facial-expression-recoginition/facial-expression.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/KaggleCode_facial-expression-recoginition/facial-expression.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs,\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/i%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/KaggleCode_facial-expression-recoginition/facial-expression.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m preds\u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39;49mnumpy() \u001b[39m# 放到cpu上去计算\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/KaggleCode_facial-expression-recoginition/facial-expression.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m result\u001b[39m.\u001b[39mextend(preds)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "net.eval()\n",
    "for data in test_loader:\n",
    "    data = data.to(device)\n",
    "    outputs = net(data)\n",
    "   \n",
    "    _, preds = torch.max(outputs,1)\n",
    "    preds= preds.cpu().numpy() # 如果要转换为numpy，则需要将位于GPU的数据传入到主存中   如果不加，\n",
    "    # 会报“can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first”错误\n",
    "    result.extend(preds)\n",
    "    #print(f\"val_pred:{val_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a90492c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:51:43.456711Z",
     "iopub.status.busy": "2023-11-13T03:51:43.455788Z",
     "iopub.status.idle": "2023-11-13T03:51:43.460412Z",
     "shell.execute_reply": "2023-11-13T03:51:43.459641Z"
    },
    "papermill": {
     "duration": 0.033534,
     "end_time": "2023-11-13T03:51:43.462326",
     "exception": false,
     "start_time": "2023-11-13T03:51:43.428792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file='submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38f5e1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T03:51:43.514255Z",
     "iopub.status.busy": "2023-11-13T03:51:43.513446Z",
     "iopub.status.idle": "2023-11-13T03:51:43.529966Z",
     "shell.execute_reply": "2023-11-13T03:51:43.529119Z"
    },
    "papermill": {
     "duration": 0.044716,
     "end_time": "2023-11-13T03:51:43.532026",
     "exception": false,
     "start_time": "2023-11-13T03:51:43.487310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in result:\n",
    "        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231f7bc",
   "metadata": {
    "papermill": {
     "duration": 0.025006,
     "end_time": "2023-11-13T03:51:43.582007",
     "exception": false,
     "start_time": "2023-11-13T03:51:43.557001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.485732,
   "end_time": "2023-11-13T03:51:45.865844",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-13T03:50:01.380112",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
